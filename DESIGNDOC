      +--------------------+
      |    EDA092/DIT400   |
      | LAB ASSIGNMENT 2:  |
      | 	THREADS      |
      |   DESIGN DOCUMENT  |
      +--------------------+

---- GROUP 19 ----

Elena Marzi <marzi@student.chalmers.se>
Johannes Magnusson <mjohann@student.chalmers.se>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

           ALARM CLOCK
           ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Additions to struct thread:
    +   int64_t sleep_until;
        Stores the time to wake up a sleeping thread.
        Gets set in timer_sleep.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When calling timer_sleep:
  The time to wake up is calculated and put in sleep_until.
  The thread is blocked by a call to thread_block.

At each timer tick, in the thread_tick function:
  All threads with a non-zero value of sleep_until are checked
  Those with a value of sleep_until that is equal to or
  smaller than the current time, are woken up by a
  call to thread_unblock

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

  We have tried three different approaches for handling sleeping
  threads: no extra list, an extra linked list, and a priority queue.

  The submitted solution uses no extra list and identifies the
  sleeping threads to wake up using thread_foreach. This gives us the
  following result:
  Timer: 934 ticks
  Thread: 550 idle ticks, 386 kernel ticks, 0 user ticks

  The second solution involved adding an extra linked list called
  sleeping_threads. By using list_insert_ordered, the list was
  kept sorted by wakeup time. That gave us the following result:
  Timer: 925 ticks
  Thread: 550 idle ticks, 378 kernel ticks, 0 user ticks

  The third solution involved writing our own priority queue
  implementation using the min-heap approach, in the prioq.c and
  prioq.h files. This approach gave us the following result:
  Timer: 926 ticks
  Thread: 550 idle ticks, 379 kernel ticks, 0 user ticks

  Even though the sorted list or the priority queue appears more
  efficient, we opted to go with the thread_foreach solution, because
  this is elegant, much more readable, and we deem it efficient
  enough.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

  The timer_sleep function only reads/writes local variables
  or parameters. Multiple calls to timer_sleep would have different
  stack pointers, which makes timer_sleep reentrant. Also, blocking
  a thread must be done with disabled interrupts.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

  The call to timer_block is done with disabled interrupts.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

  As discussed in depth in A3 above, we chose this design because it
  appears to be more elegant and readable.

  Also, we first tried using a semaphore for making the thread sleep,
  but realized that the code we were writing is internal to the thread
  mechanism, and that a simple thread_block and thread_unblock is enough.

          BATCH SCHEDULING
          ================
---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, semaphore, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Lock for synchronizing coordinated operations:

static struct lock sync_lock;

Variables for counting number of runnings tasks of different categories.
These are used to keep track of the current direction of the bus, and
also the current highest priority level of tasks on the bus:

static int senders_running = 0;
static int receivers_running = 0;
static int high_priority_running = 0;

Variables for counting number of waiting tasks of different categories.
These are used to know what type of tasks to wake up when one task is
done:

static int high_prio_senders_waiting = 0;
static int high_prio_receivers_waiting = 0;
static int low_prio_senders_waiting = 0;
static int low_prio_receivers_waiting = 0;

Condition variables for waiting tasks to use. These are used to wake
up single tasks or groups of tasks when one task is done:

static struct condition high_prio_senders_cond;
static struct condition high_prio_receivers_cond;
static struct condition low_prio_senders_cond;
static struct condition low_prio_receivers_cond;

---- SYNCHRONIZATION ----

>> C1: How does your solution guarantee that no more than 3 tasks
>> are using the bus in the same direction?

  The solution is based on the Old Bridge Problem. When a task
  tries to start, in the getSlot function, if the bus is full,
  the task waits for a condition variable before retrying to start.

  Which condition variable the task waits for depends on its
  priority and direction.

  In the leaveSlot function, when a SINGLE new task should be
  allowed, for exemple when a HIGH priority SENDER is done, and
  there is at least one HIGH priority SENDER waiting to start,
  the corresponding condition variable is signalled, because we
  can assume that the "one out : one in" principle can apply.

  When MULTIPLE new tasks could be allowed, for example when the
  last SENDER is done, and there are multiple RECEIVERs waiting
  to start, the corresponding condition variable is broadcasted,
  instead of just signalled.

>> C2: What prevents tasks from opposite directions from using the
>> bus simultaneously?

  When a task tries to start, in the getSlot function, if the task
  is a SENDER and at least one RECEIVER is currently using the bus,
  or it is a RECEIVER and at least one SENDER is using the bus,
  the task waits for a condition variable before retrying to start.

>> C3: How does your solution grant priority to high priority tasks over
>> the waiting tasks in the same direction?

  When a task tries to start, in the getSlot function, if the task
  has NORMAL priority and at least one HIGH priority task is running, or
  at least one HIGH priority task of the same direction is waiting to
  run, the task waits for a condition variable before retrying to start.

>> C4: How do you guarantee that despite having priority, high priority
>> tasks do not start using the bus while there are still tasks using
>> it in the oposite direction?

  Even if the task's priority is HIGH, if any task of the opposite
  direction is currently running, the priority of the other task is
  not taken into consideration, so the new task waits.

---- RATIONALE ----

>> C6: Why did you choose this design? Did you consider other design 
>> alternatives? In what ways is it superior to another design you considered?

  At first, we tried using a combination of semaphores and condition variables
  where semaphores were used to count running tasks of different kinds.
  
  It seemed to work properly, but we wanted to test it further, so instead of
  starting threads in a neat order, we changed the batchScheduler function so
  that it now starts threads in random order. That helped us discover a lot
  of bugs, so we introduced a lot of extra control mechanisms. We eventually
  got it working, but the solution was too complex.

  Instead, we made this solution as an extension of the Old Bridge Problem.
  Now it is much more easy to understand, and it is probably more efficient.

         SURVEY QUESTIONS (optional)
         ===========================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

  We found this assignment very difficult. Even though we thought we
  understood enough to solve the problems, our first solutions were
  not very optimized. It has taken us much more time than we thought.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

  Threads are a new concept for us, and even if synchronization was
  one topic from a previous course on real time systems, this is the
  first time we go into this level of depth.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters?

  Hire more assistants.

>> Any other comments?
