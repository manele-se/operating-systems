      +--------------------+
      |    EDA092/DIT400   |
      | LAB ASSIGNMENT 2:  |
      | 	THREADS      |
      |   DESIGN DOCUMENT  |
      +--------------------+

---- GROUP 19 ----

Elena Marzi <marzi@student.chalmers.se>
Johannes Magnusson <mjohann@student.chalmers.se>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

           ALARM CLOCK
           ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Additions to struct thread:
    +   int64_t sleep_until;
        Stores the time to wake up a sleeping thread.
        Gets set in timer_sleep.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When calling timer_sleep:
  The time to wake up is calculated and put in sleep_until.
  The thread is blocked by a call to thread_block

At each timer tick, in the thread_tick function:
  All threads with a non-zero value of sleep_until are checked
  Those with a value of sleep_until that is equal to or
  smaller than the current time, are woken up by a
  call to thread_unblock

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

  We have tried three different approaches for handling sleeping
  threads: no extra list, an extra linked list, and a priority queue.

  The submitted solution uses no extra list and identifies the
  sleeping threads to wakt up using thread_foreach. This gives us the
  following result:
  Timer: 934 ticks
  Thread: 550 idle ticks, 386 kernel ticks, 0 user ticks

  The second solution involved adding an extra struct list called
  sleeping_threads. By using list_insert_ordered, the list was
  kept sorted by wakeup time. That gave us the following result:
  Timer: 925 ticks
  Thread: 550 idle ticks, 378 kernel ticks, 0 user ticks

  The third solution involved writing our own priority queue
  implementation using the min-heap approach, in the prioq.c and
  prioq.h files. This approach gave us the following result:
  Timer: 926 ticks
  Thread: 550 idle ticks, 379 kernel ticks, 0 user ticks

  Even though the sorted list or the priority queue appears more
  efficient, we opted to go with the thread_foreach solution, because
  this is elegant, much more readable, and we deem it efficient
  enough.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

  The timer_sleep function only reads/writes local variables
  or parameters. Multiple calls to timer_sleep would have different
  stack pointers, which makes timer_sleep reentrant. Also, blocking
  a thread must be done with disabled interrupts.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

  The call to timer_block is done with disabled interrupts.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

  As discussed indepth in A3 above, we chose this design because it
  appears to be more elegant and readable.

          BATCH SCHEDULING
          ================
---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, semaphore, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Lock for synchronizing coordinated semaphore operations:
struct lock sync_lock;

Semaphore that keeps track of number of running threads:
struct semaphore running_sema;

Semaphore that lets main thread wait for all running threads:
struct semaphore main_wait_sema;

Semaphore that keeps track of high-priority sender and receiver
threads, waiting for a slot:
struct semaphore high_senders_sema;
struct semaphore high_receivers_sema;

Condition variable that lets low priority threads wait until all
high priority threads are done:
struct condition high_prio_cond;

Condition variable that signals to all threads to start:
struct condition start_all_cond;

Semaphore that keeps the maximum connections to BUS_CAPACITY:
struct semaphore capacity_sema;

Semaphores that keep track of currently sending/receiving tasks:
struct semaphore senders_sema;
struct semaphore receivers_sema;

Condition variables that signal:
 - to senders that no task is receiving
 - to receivers that no task is sending
struct condition sending_ok_cond;
struct condition receiving_ok_cond;

---- SYNCHRONIZATION ----

>> C1: How does your solution guarantee that no more that 3 tasks
>> are using the bus in the same direction?

  There is a semaphore called capacity_sema, which is initialized
  with the value 3 (BUS_CAPACITY) in bus_init.

  When a task starts, it pulls that semaphore down, in the getSlot function.

  When a task ends, it pulls that semaphore up, in the leaveSlot function.

>> C2: What prevents tasks from opposite directions from using the
>> bus simultaneously?

  When a sender starts, it pulls the senders_sema semaphore up, to count
  the number of current senders. When a sender ends, it pulls the
  senders_sema semaphore down. If the value reaches 0, it does a broadcast
  on the receiving_ok_cond condition variable.

  If a receiver tries to start when the senders_sema value is > 0, it
  waits for the receiving_ok_cond to get signalled.

  Vice versa for the other direction.

>> C3: How does your solution grant priority to high priority tasks over
>> the waiting tasks in the same direction?

  When a high priority task starts, it pulls either the high_senders_sema
  or the high_receivers_sema up. When that task ends, it pulls the same
  semaphore down. If the sum after pulling down is 0, it does a broadcast
  on the high_prio_cond condition variable.

  When a low priority task starts, and the sum of high_senders_sema and
  high_receivers_sema > 0, it waits for the high_prio_cond condition
  variable.

>> C4: How do you guarantee that despite having priority, high priority
>> tasks do not start using the bus while there are still tasks using
>> it in the oposite direction?

  The combination of C2 and C3 solves this. Also the order of semaphore
  and condition variable operations guarantees this.

  The getSlot function does not finish until all requirements are
  fulfilled. So for example, if a low priority task is sending, and a
  new high priority receiver task arrives, it sees that senders_sema has
  a non-zero value, and waits for the receiving_ok_cond to get signalled.

---- RATIONALE ----

>> C6: Why did you choose this design? Did you consider other design 
>> alternatives? In what ways is it superior to another design you considered?


			   SURVEY QUESTIONS (optional)
			   ===========================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters?

>> Any other comments?
