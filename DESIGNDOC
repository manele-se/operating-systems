			+--------------------+
			|    EDA092/DIT400   |
			| LAB ASSIGNMENT 2:  |
			| 	THREADS      |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP 19 ----

Elena Marzi <marzi@student.chalmers.se>
Johannes Magnusson <mjohann@student.chalmers.se>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Additions to struct thread:
    +   struct semaphore sleep_semaphore;
	    Semaphore for blocking and unblocking the thread.
		Gets initialized to zero in init_thread.

    +   int64_t sleep_until;
        Stores the time to wake up a sleeping thread.
		Gets set in timer_sleep.

Later addition to thread.c:
    +   struct list sleeping_threads;
	    Global ordered list of sleeping threads, sorted
		by time to wake up (sleep_until).

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When calling timer_sleep:
  The time to wake up is calculated and put in sleep_until.
  The thread's sleep semaphore is decreased, which blocks the thread.
  The thread is added to the list of sleeping threads.

At each timer tick, in the thread_tick function:
  The threads that are in the list of sleeping threads are checked.
  Those threads that are due to wake up:
    Their sleep semaphore is increased, which unblocks the thread.
  The list is ordered by wakeup time.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

  The first solution, which is left in the code as comments, used
  thread_foreach in each thread_tick to loop through all threads and
  wake up those that were due to wake up. This was not
  efficient enough : O(n).

  Instead, an ordered list has been created. Because it is sorted
  by wakeup time, checking for threads to wake up is O(1). The list is a 
  linked list, so we assumed that insertion would be slow. Therefore, we
  wrote a priority queue implementation, which is also left in the code
  as comments, for reference.

  After testing, we obtained the following results:

  Linked list:
  Timer: 925 ticks
  Thread: 550 idle ticks, 378 kernel ticks, 0 user ticks

  Priority queue:
  Timer: 926 ticks
  Thread: 550 idle ticks, 379 kernel ticks, 0 user ticks

  Therefore, we chose to go back to the linked list solution. It appears
  the O(log n) time for removing from a priority queue added too much
  overhead, even though insertion probably is more efficient.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

  Each thread has its own semaphore, which gives each thread a separate
  mechanism for knowing when to wake up.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

  Adding to the list of sleeping threads takes place between
  intr_disable and intr_enable, so that the sensitive list insertion
  code runs without being interrupted.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

  As discussed indepth in A3 above, we chose this design because it appears to
  be the most efficient in terms of time spent in timer interrupt.

			    BATCH SCHEDULING
			    ================
---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, semaphore, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Lock for synchronizing coordinated semaphore operations:
struct lock sync_lock;

Semaphore that keeps track of number of running threads:
struct semaphore running_sema;

Semaphore that lets main thread wait for all running threads:
struct semaphore main_wait_sema;

Semaphore that keeps track of high-priority sender and receiver
threads, waiting for a slot:
struct semaphore high_senders_sema;
struct semaphore high_receivers_sema;

Condition variable that lets low priority threads wait until all
high priority threads are done:
struct condition high_prio_cond;

Condition variable that signals to all threads to start:
struct condition start_all_cond;

Semaphore that keeps the maximum connections to BUS_CAPACITY:
struct semaphore capacity_sema;

Semaphores that keep track of currently sending/receiving tasks:
struct semaphore senders_sema;
struct semaphore receivers_sema;

Condition variables that signal:
 - to senders that no task is receiving
 - to receivers that no task is sending
struct condition sending_ok_cond;
struct condition receiving_ok_cond;

---- SYNCHRONIZATION ----

>> C1: How does your solution guarantee that no more that 3 tasks
>> are using the bus in the same direction?

  There is a semaphore called capacity_sema, which is initialized
  with the value 3 (BUS_CAPACITY) in bus_init.

  When a task starts, it pulls that semaphore down, in the getSlot function.

  When a task ends, it pulls that semaphore up, in the leaveSlot function.

>> C2: What prevents tasks from opposite directions from using the
>> bus simultaneously?

  When a sender starts, it pulls the senders_sema semaphore up, to count
  the number of current senders. When a sender ends, it pulls the
  senders_sema semaphore down. If the value reaches 0, it does a broadcast
  on the receiving_ok_cond condition variable.

  If a receiver tries to start when the senders_sema value is > 0, it
  waits for the receiving_ok_cond to get signalled.

  Vice versa for the other direction.

>> C3: How does your solution grant priority to high priority tasks over
>> the waiting tasks in the same direction?

  When a high priority task starts, it pulls either the high_senders_sema
  or the high_receivers_sema up. When that task ends, it pulls the same
  semaphore down. If the sum after pulling down is 0, it does a broadcast
  on the high_prio_cond condition variable.

  When a low priority task starts, and the sum of high_senders_sema and
  high_receivers_sema > 0, it waits for the high_prio_cond condition
  variable.

>> C4: How do you guarantee that despite having priority, high priority
>> tasks do not start using the bus while there are still tasks using
>> it in the oposite direction?

  The combination of C2 and C3 solves this. Also the order of semaphore
  and condition variable operations guarantees this.

  The getSlot function does not finish until all requirements are
  fulfilled. So for example, if a low priority task is sending, and a
  new high priority receiver task arrives, it sees that senders_sema has
  a non-zero value, and waits for the receiving_ok_cond to get signalled.

---- RATIONALE ----

>> C6: Why did you choose this design? Did you consider other design 
>> alternatives? In what ways is it superior to another design you considered?


			   SURVEY QUESTIONS (optional)
			   ===========================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters?

>> Any other comments?
